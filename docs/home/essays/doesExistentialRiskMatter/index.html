<!DOCTYPE html><html lang="en-US"><head><title data-react-helmet="true">Directory</title><link rel="preload" as="script" href="/bootstrap.bd1d042d.js"/><link rel="preload" as="script" href="/templates/src/containers/Note.4d41f4ed.js"/><link rel="preload" as="script" href="/main.7578e5b0.js"/><link rel="preload" as="style" href="/styles.f4bf7be5.css"/><link rel="stylesheet" href="/styles.f4bf7be5.css"/><link data-react-helmet="true" rel="icon" type="image/png" href="/favicon.png"/><meta charSet="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, shrink-to-fit=no"/></head><body><div id="root"><div data-reactroot=""><div class="content"><div><div class="header--secondary"><div class="container"><h2 class="back-button"><a class="active" aria-current="page" href="/home/essays">Essays<!-- --> <i class="mdi mdi-subdirectory-arrow-left back-icon"></i></a></h2><h1>Does Existential Risk Matter</h1></div></div><div class="container"><div class="row"></div></div><div class="text"><div class="container"><div class="row"><div class="col-md-8 offset-md-2"><p>An existential catastrophe is an event which would cause the extinction of earth-originating intelligent life or permanently and drastically curtail its potential. An existential risk is an event which could cause an existential catastrophe.</p>
<p>I think the question of whether existential risk matters is really important because an existential catastrophe would be such an impactful event. Therefore any effort put into understanding or reducing existential risk could have a very large positive impact.</p>
<p>For instance, an informal poll in 2008 at a conference on catastrophic risks found they believe it’s pretty likely we’ll face a catastrophe that kills over a billion people, and estimate a 19% chance of extinction before 2100.</p>
<h3 id="why-could-existential-risk-be-important-">Why Could Existential Risk be Important?</h3>
<p>If an existential catastrophe occurred, everyone who would have come into existence in the future had the event not occurred would not come into existence. If we value each other those future individuals as much as we value the lives of people today, then humanity would lose almost all of its future potential - a tremendously large loss. Earth originating intelligent life has the potential to survive for trillions of years. Therefore the total number of people or other types of minds that could exist in that time period would be extremely large and the ratio of the number of future people to people currently alive would be very high. If we value each of these potential lives as much as we value people currently alive, then our actions should overwhelmingly be determined by their effect on our descendants.</p>
<h3 id="should-we-discount-the-value-of-future-people-">Should We Discount the Value of Future People?</h3>
<p>But the position I explained above assumes that each future descendant is as valuable as people currently alive today. Does that make sense? Personally, I'm not sure whether we should value each of our descendants live's as much as we value our own or whether we should discount the value of their lives. In the book "Superintelligence", Nick Bostrom estimates that our universe could support at least 10 ^ 58 lives in its entire future (including computer-emulated minds). Even if we decided to discount the value of future lives relative to the value of people currently alive by a factor of one thousand (where the value of 1 person currently alive = the value of 1000 future people), the total value of our future descendants would still outweigh the value of all people currently alive by a factor of 10 ^ 45 (1).</p>
<p>Decision theory says that we should make a list of all possible outcomes, determine the positive or negative value for each outcome and multiply the probability of each outcome by each value to calculate the expected value (2). For example, dropping and breaking your phone is a possible outcome which could have a negative expected value of -5 (depends on the person). If the probability of this outcome occurring is 0.5, then the expected value is -5 x 0.5 = -2.5.</p>
<p>Above I explained how the the total value of all our future descendants could be worth 10 ^ 45 times more than the total value of all people alive today. However, I made this decision under uncertainty because I am not sure if my assumptions are true. Applying decision theory to the problem helps to deal with this uncertainty. Even if we decide that the above conclusion has only a 1% chance of being true, then the expected value is (10 ^ 45) x 0.01 = 10 ^ 43. This means that even when the uncertainty of the conclusion above is taken into account the value of our descendants is still 10 ^ 43 times greater than the value of all people alive today.</p>
<h3 id="how-does-this-inform-our-actions-as-a-society-">How Does This Inform Our Actions as a Society?</h3>
<p>It may be true that how our actions affect our descendants matters much more than how they affect us as calculated above. However, this conclusion is blemished by a high level of uncertainty - should we discount the value of future people? If so how much? Should we even value them? We could ask what's in it for us to provide a good future for our descendants or it could also be argued that events that matter beyond your death don't have value since you can't perceive them. On the other hand, it's difficult to disprove the hypothesis that our descendants matter. Many people consider putting the interests of the current generation above future generations to be selfish.</p>
<p>Against this backdrop of great uncertainty, how should we act as a society? Since there is so much uncertainty, it makes sense for us to prepare for the possibility that we are wrong. In the future, people might discover that the future is incredibly important or not; but right now we simply don't know what the true answer is. As a society, the most rational thing to do is to spread our bets in case we are wrong. Putting all our eggs in one basket and betting on one answer is risky. Instead, it makes sense to apply effort to both directions - to look after the interests of current and future people.</p>
<p>I think the balance is tipped a little too far towards the interests of people current alive and too little effort is being put into the long term future. This makes sense because, as humans, our natural tendency is to focus on the short term. In my opinion,  the world would be better if we put a more effort towards looking after the interests of our descendants.</p>
<ul>
<li>Luxury goods: ~$1.3 trillion (<a href="https://web.archive.org/web/20171020234247/http://www.bain.com/publications/articles/luxury-goods-worldwide-market-study-fall-winter-2016.aspx">source</a>)</li>
<li>Spending on AI safety research per year: ~$10 million (<a href="https://aiimpacts.org/changes-in-funding-in-the-ai-safety-field/">source</a>)</li>
</ul>
<p>Are luxury goods really 100,000 times more important than AI safety? (100,000 times more money is spent on luxury goods than AI safety.)</p>
<h3 id="what-about-the-individual-">What About the Individual?</h3>
<p>The specialization of labor applies here. The idea is that when everyone focuses on what they are good at, society ends up better off. It is more efficient to have a doctor and a programmer than two people who can do both. Focus on areas that are neglected because it's not that valuable to be the millionth something. Ask yourself what kind of work would lead to the most positive value in the world for yourself and others. Personally, I'm interested in AI safety because it's a neglected field relative to the magnitude of the consequences AI could have in the future.</p>
<h3 id="conclusion">Conclusion</h3>
<p>I have calculated that the total aggregate value of our descendants is vastly greater than the aggregate value of all people based on some shaky assumptions (3). Though even when a high discount factor (1000) is applied to the value of future lives and the conclusion is weakened by a factor of 100 due to uncertainty about whether or not it is true, the conclusion still holds - the total value of our future descendants is much greater than the total value of all people today if some shaky assumptions hold true.</p>
<p>It's unclear whether this conclusion is true, perhaps it could be completely wrong. However, it would be unwise to risk putting all our eggs in one basket. It would be arrogant to assume that we know which answer is correct given that so many variables have uncertain values. Therefore, as a society, it makes sense to direct some effort in both directions in case either direction is the right one.</p>
<p>Though, at present, it seems like the balance is tipped too far in favor of short term interests over the long term future. It think it would be better if we thought more about the long term and the interests of our future descendants. </p>
<h3 id="notes">Notes</h3>
<p>(1) - calculations:</p>
<ul>
<li>current world population: 8 * 10 ^ 9 (based on the 2019 estimate and rounded upward)</li>
<li>assuming each current person's live is worth 1 unit of value, the total value of all people currently alive is (8 * 10 ^ 9) x 1 = 8 * 10 ^ 9 units of value</li>
<li>If we apply a discount factor of 1000 to our future descendants, then each future descendant is worth 1/1000 or 0.001 units of value</li>
<li>The total value of all future descendants = 0.001 * (10 ^ 58) = 10 ^ 55</li>
<li>Ratio of the total value of our descendants to the total value of all people currently alive: (10 ^ 55) / (8 * 10 ^ 9) = 1.25 * 10 ^ 45</li>
</ul>
<p>(3) - Assumptions:</p>
<ul>
<li>These calculations assume that the value of lives aggregates (ie. two people is twice as valuable as one person) and that each life have positive value (in other words, that the lives are of a sufficient quality that they are worth living)</li>
</ul>
<p>(2) - <a href="https://en.wikipedia.org/wiki/Decision_theory#Choice_under_uncertainty">source</a></p>
<ul>
<li>Credit: this article was inspired by an argument which was originally explained by Nick Bostrom in his book 'Superintelligence'</li>
</ul>
</div></div></div></div></div></div></div></div><script type="text/javascript">window.__CSS_CHUNKS__ = {"main":"/styles.f4bf7be5.css"}</script><script type="text/javascript">
    window.__routeInfo = {"path":"home/essays/doesExistentialRiskMatter","templateID":2,"sharedPropsHashes":{},"localProps":null,"allProps":{"note":{"path":"home/essays/doesExistentialRiskMatter","name":"Does Existential Risk Matter","parent":"home/essays","contents":"<p>An existential catastrophe is an event which would cause the extinction of earth-originating intelligent life or permanently and drastically curtail its potential. An existential risk is an event which could cause an existential catastrophe.</p>\n<p>I think the question of whether existential risk matters is really important because an existential catastrophe would be such an impactful event. Therefore any effort put into understanding or reducing existential risk could have a very large positive impact.</p>\n<p>For instance, an informal poll in 2008 at a conference on catastrophic risks found they believe it’s pretty likely we’ll face a catastrophe that kills over a billion people, and estimate a 19% chance of extinction before 2100.</p>\n<h3 id=\"why-could-existential-risk-be-important-\">Why Could Existential Risk be Important?</h3>\n<p>If an existential catastrophe occurred, everyone who would have come into existence in the future had the event not occurred would not come into existence. If we value each other those future individuals as much as we value the lives of people today, then humanity would lose almost all of its future potential - a tremendously large loss. Earth originating intelligent life has the potential to survive for trillions of years. Therefore the total number of people or other types of minds that could exist in that time period would be extremely large and the ratio of the number of future people to people currently alive would be very high. If we value each of these potential lives as much as we value people currently alive, then our actions should overwhelmingly be determined by their effect on our descendants.</p>\n<h3 id=\"should-we-discount-the-value-of-future-people-\">Should We Discount the Value of Future People?</h3>\n<p>But the position I explained above assumes that each future descendant is as valuable as people currently alive today. Does that make sense? Personally, I&#39;m not sure whether we should value each of our descendants live&#39;s as much as we value our own or whether we should discount the value of their lives. In the book &quot;Superintelligence&quot;, Nick Bostrom estimates that our universe could support at least 10 ^ 58 lives in its entire future (including computer-emulated minds). Even if we decided to discount the value of future lives relative to the value of people currently alive by a factor of one thousand (where the value of 1 person currently alive = the value of 1000 future people), the total value of our future descendants would still outweigh the value of all people currently alive by a factor of 10 ^ 45 (1).</p>\n<p>Decision theory says that we should make a list of all possible outcomes, determine the positive or negative value for each outcome and multiply the probability of each outcome by each value to calculate the expected value (2). For example, dropping and breaking your phone is a possible outcome which could have a negative expected value of -5 (depends on the person). If the probability of this outcome occurring is 0.5, then the expected value is -5 x 0.5 = -2.5.</p>\n<p>Above I explained how the the total value of all our future descendants could be worth 10 ^ 45 times more than the total value of all people alive today. However, I made this decision under uncertainty because I am not sure if my assumptions are true. Applying decision theory to the problem helps to deal with this uncertainty. Even if we decide that the above conclusion has only a 1% chance of being true, then the expected value is (10 ^ 45) x 0.01 = 10 ^ 43. This means that even when the uncertainty of the conclusion above is taken into account the value of our descendants is still 10 ^ 43 times greater than the value of all people alive today.</p>\n<h3 id=\"how-does-this-inform-our-actions-as-a-society-\">How Does This Inform Our Actions as a Society?</h3>\n<p>It may be true that how our actions affect our descendants matters much more than how they affect us as calculated above. However, this conclusion is blemished by a high level of uncertainty - should we discount the value of future people? If so how much? Should we even value them? We could ask what&#39;s in it for us to provide a good future for our descendants or it could also be argued that events that matter beyond your death don&#39;t have value since you can&#39;t perceive them. On the other hand, it&#39;s difficult to disprove the hypothesis that our descendants matter. Many people consider putting the interests of the current generation above future generations to be selfish.</p>\n<p>Against this backdrop of great uncertainty, how should we act as a society? Since there is so much uncertainty, it makes sense for us to prepare for the possibility that we are wrong. In the future, people might discover that the future is incredibly important or not; but right now we simply don&#39;t know what the true answer is. As a society, the most rational thing to do is to spread our bets in case we are wrong. Putting all our eggs in one basket and betting on one answer is risky. Instead, it makes sense to apply effort to both directions - to look after the interests of current and future people.</p>\n<p>I think the balance is tipped a little too far towards the interests of people current alive and too little effort is being put into the long term future. This makes sense because, as humans, our natural tendency is to focus on the short term. In my opinion,  the world would be better if we put a more effort towards looking after the interests of our descendants.</p>\n<ul>\n<li>Luxury goods: ~$1.3 trillion (<a href=\"https://web.archive.org/web/20171020234247/http://www.bain.com/publications/articles/luxury-goods-worldwide-market-study-fall-winter-2016.aspx\">source</a>)</li>\n<li>Spending on AI safety research per year: ~$10 million (<a href=\"https://aiimpacts.org/changes-in-funding-in-the-ai-safety-field/\">source</a>)</li>\n</ul>\n<p>Are luxury goods really 100,000 times more important than AI safety? (100,000 times more money is spent on luxury goods than AI safety.)</p>\n<h3 id=\"what-about-the-individual-\">What About the Individual?</h3>\n<p>The specialization of labor applies here. The idea is that when everyone focuses on what they are good at, society ends up better off. It is more efficient to have a doctor and a programmer than two people who can do both. Focus on areas that are neglected because it&#39;s not that valuable to be the millionth something. Ask yourself what kind of work would lead to the most positive value in the world for yourself and others. Personally, I&#39;m interested in AI safety because it&#39;s a neglected field relative to the magnitude of the consequences AI could have in the future.</p>\n<h3 id=\"conclusion\">Conclusion</h3>\n<p>I have calculated that the total aggregate value of our descendants is vastly greater than the aggregate value of all people based on some shaky assumptions (3). Though even when a high discount factor (1000) is applied to the value of future lives and the conclusion is weakened by a factor of 100 due to uncertainty about whether or not it is true, the conclusion still holds - the total value of our future descendants is much greater than the total value of all people today if some shaky assumptions hold true.</p>\n<p>It&#39;s unclear whether this conclusion is true, perhaps it could be completely wrong. However, it would be unwise to risk putting all our eggs in one basket. It would be arrogant to assume that we know which answer is correct given that so many variables have uncertain values. Therefore, as a society, it makes sense to direct some effort in both directions in case either direction is the right one.</p>\n<p>Though, at present, it seems like the balance is tipped too far in favor of short term interests over the long term future. It think it would be better if we thought more about the long term and the interests of our future descendants. </p>\n<h3 id=\"notes\">Notes</h3>\n<p>(1) - calculations:</p>\n<ul>\n<li>current world population: 8 * 10 ^ 9 (based on the 2019 estimate and rounded upward)</li>\n<li>assuming each current person&#39;s live is worth 1 unit of value, the total value of all people currently alive is (8 * 10 ^ 9) x 1 = 8 * 10 ^ 9 units of value</li>\n<li>If we apply a discount factor of 1000 to our future descendants, then each future descendant is worth 1/1000 or 0.001 units of value</li>\n<li>The total value of all future descendants = 0.001 * (10 ^ 58) = 10 ^ 55</li>\n<li>Ratio of the total value of our descendants to the total value of all people currently alive: (10 ^ 55) / (8 * 10 ^ 9) = 1.25 * 10 ^ 45</li>\n</ul>\n<p>(3) - Assumptions:</p>\n<ul>\n<li>These calculations assume that the value of lives aggregates (ie. two people is twice as valuable as one person) and that each life have positive value (in other words, that the lives are of a sufficient quality that they are worth living)</li>\n</ul>\n<p>(2) - <a href=\"https://en.wikipedia.org/wiki/Decision_theory#Choice_under_uncertainty\">source</a></p>\n<ul>\n<li>Credit: this article was inspired by an argument which was originally explained by Nick Bostrom in his book &#39;Superintelligence&#39;</li>\n</ul>\n","folder":0},"children_notes":[]},"siteData":{"title":"React Static"}};</script><script defer="" type="text/javascript" src="/bootstrap.bd1d042d.js"></script><script defer="" type="text/javascript" src="/templates/src/containers/Note.4d41f4ed.js"></script><script defer="" type="text/javascript" src="/main.7578e5b0.js"></script></body></html>